{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "977a22de",
   "metadata": {},
   "source": [
    "### Packages Required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a811d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b498a23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Dropout\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268ea169",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69b0773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/Nithin/Downloads/Google Stock Prediction_AI_Forecasting/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f23ce6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(path+'Datasets/train.csv')\n",
    "test_df = pd.read_csv(path+'Datasets/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70acf9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df.iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e23f50b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_df.iloc[:,1:2].values\n",
    "total_df = pd.concat([train_df['Open'],test_df['Open']],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "203e9d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 955.48999 ,  966.700012,  980.      ,  980.      ,  973.719971,\n",
       "        987.450012,  992.      ,  992.099976,  990.289978,  991.77002 ,\n",
       "        986.      ,  989.440002,  989.52002 ,  970.      ,  968.369995,\n",
       "        980.      , 1009.190002, 1014.      , 1015.219971, 1017.210022,\n",
       "       1021.76001 , 1022.109985, 1028.98999 , 1027.27002 , 1030.52002 ,\n",
       "       1033.98999 , 1026.459961, 1023.419983, 1022.590027, 1019.210022,\n",
       "       1022.52002 , 1034.01001 , 1020.26001 , 1023.309998, 1035.      ,\n",
       "       1035.869995, 1040.      , 1055.089966, 1042.680054, 1022.369995,\n",
       "       1015.799988, 1012.659973,  995.940002, 1001.5     , 1020.429993,\n",
       "       1037.48999 , 1035.5     , 1039.630005, 1046.119995, 1045.      ,\n",
       "       1054.609985, 1066.079956, 1075.199951, 1071.780029, 1064.949951,\n",
       "       1061.109985, 1058.069946, 1057.390015, 1051.599976, 1046.719971,\n",
       "       1048.339966, 1064.310059, 1088.      , 1094.      , 1102.22998 ,\n",
       "       1109.400024, 1097.099976, 1106.300049, 1102.410034, 1132.51001 ,\n",
       "       1126.219971, 1131.410034, 1131.829956, 1137.48999 , 1159.849976,\n",
       "       1177.329956, 1172.530029, 1175.079956, 1176.47998 , 1167.829956,\n",
       "       1170.569946, 1162.609985, 1122.      , 1090.599976, 1027.180054,\n",
       "       1081.540039, 1055.410034, 1017.25    , 1048.      , 1045.      ,\n",
       "       1048.949951, 1079.069946, 1088.410034, 1090.569946, 1106.469971,\n",
       "       1116.189941, 1112.640015, 1127.800049, 1141.23999 , 1123.030029,\n",
       "       1107.869995, 1053.079956, 1075.140015, 1099.219971, 1089.189941,\n",
       "       1115.319946, 1136.      , 1163.849976, 1170.      , 1145.209961,\n",
       "       1149.959961, 1154.140015, 1120.01001 , 1099.      , 1092.73999 ,\n",
       "       1081.880005, 1047.030029, 1046.      , 1063.      ,  998.      ,\n",
       "       1011.630005, 1022.820007, 1013.909973,  993.409973, 1041.329956,\n",
       "       1020.      , 1016.799988, 1026.439941, 1027.98999 , 1025.040039,\n",
       "       1040.880005, 1037.      , 1051.369995, 1077.430054, 1069.400024,\n",
       "       1082.      , 1077.859985, 1052.      , 1025.52002 , 1029.51001 ,\n",
       "       1046.      , 1030.01001 , 1013.659973, 1028.099976, 1019.      ,\n",
       "       1016.900024, 1049.22998 , 1058.540039, 1058.099976, 1086.030029,\n",
       "       1093.599976, 1100.      , 1090.      , 1077.310059, 1079.890015,\n",
       "       1061.859985, 1074.060059, 1083.560059, 1065.130005, 1079.      ,\n",
       "       1079.02002 , 1064.890015, 1063.030029, 1067.560059, 1099.349976,\n",
       "       1122.329956, 1140.98999 , 1142.170044, 1131.319946, 1118.180054,\n",
       "       1118.599976, 1131.069946, 1141.119995, 1143.849976, 1148.859985,\n",
       "       1143.650024, 1158.5     , 1175.310059, 1174.849976, 1159.140015,\n",
       "       1143.599976, 1128.      , 1121.339966, 1102.089966, 1120.      ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df[len(total_df)-len(test)-60:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaf8e7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = total_df[len(total_df)-len(test)-60:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a96047c",
   "metadata": {},
   "source": [
    "**-- Standardise the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebaa2deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "train_std = sc.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8115d90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs.reshape(-1,1)\n",
    "test_std = sc.transform(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "417e619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "for i in range(60,train_std.size):\n",
    "    train_x.append(train_std[i-60:i,0])\n",
    "    train_y.append(train_std[i,0])\n",
    "    \n",
    "train_x,train_y = np.array(train_x),np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0176f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = []\n",
    "\n",
    "for i in range(60,test_std.size):\n",
    "    test_x.append(inputs[i-60:i,0])\n",
    "    \n",
    "test_x = np.array(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e92727a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.resize(train_x,[train_x.shape[0],train_x.shape[1],1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99b67017",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = np.resize(test_x,[test_x.shape[0],test_x.shape[1],1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e252a595",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "229b5f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--> Intialise Model\n",
    "M0 = Sequential()\n",
    "#--> 1st Layer\n",
    "M0.add(LSTM(units=50,return_sequences=True,input_shape=(train_x.shape[1],1)))\n",
    "M0.add(Dropout(0.2))\n",
    "#--> 2nd Layer\n",
    "M0.add(LSTM(units=50,return_sequences=True))\n",
    "M0.add(Dropout(0.2))\n",
    "#--> 3rd Layer\n",
    "M0.add(LSTM(units=50,return_sequences=True))\n",
    "M0.add(Dropout(0.2))\n",
    "#--> 4th Layer\n",
    "M0.add(LSTM(units=50,return_sequences=True))\n",
    "M0.add(Dropout(0.2))\n",
    "#--> 5th Layer\n",
    "M0.add(LSTM(units=50))\n",
    "M0.add(Dropout(0.2))\n",
    "#-->Output layer\n",
    "M0.add(Dense(units=1))\n",
    "\n",
    "#--> Compile\n",
    "M0.compile(optimizer='adam',loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fdd0316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 9s 72ms/step - loss: 0.0270\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 3s 71ms/step - loss: 0.0048\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 3s 67ms/step - loss: 0.0047\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 3s 70ms/step - loss: 0.0042\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 3s 72ms/step - loss: 0.0039\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 3s 88ms/step - loss: 0.0039\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 3s 85ms/step - loss: 0.0040\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 0.0035\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 3s 87ms/step - loss: 0.0034\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 3s 85ms/step - loss: 0.0041\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 3s 87ms/step - loss: 0.0034\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.0032\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 3s 86ms/step - loss: 0.0036\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 3s 88ms/step - loss: 0.0031\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 3s 87ms/step - loss: 0.0037\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.0030\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.0031\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 0.0027\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 3s 87ms/step - loss: 0.0028\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 0.0028\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 4s 93ms/step - loss: 0.0031\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 4s 100ms/step - loss: 0.0030\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 4s 99ms/step - loss: 0.0027\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 4s 93ms/step - loss: 0.0025\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 3s 86ms/step - loss: 0.0028\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.0025\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 3s 83ms/step - loss: 0.0026\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 3s 88ms/step - loss: 0.0025\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 3s 86ms/step - loss: 0.0023\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 4s 94ms/step - loss: 0.0024\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 4s 96ms/step - loss: 0.0024\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 4s 105ms/step - loss: 0.0023\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 4s 107ms/step - loss: 0.0024\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 5s 143ms/step - loss: 0.0023\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 0.0022\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 4s 117ms/step - loss: 0.0024\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 7s 181ms/step - loss: 0.0019\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 6s 145ms/step - loss: 0.0021\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 4s 95ms/step - loss: 0.0020\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 0.0021\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 0.0020\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 3s 88ms/step - loss: 0.0020\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 3s 88ms/step - loss: 0.0019\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 4s 103ms/step - loss: 0.0021\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 4s 103ms/step - loss: 0.0019\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 3s 88ms/step - loss: 0.0018\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 4s 106ms/step - loss: 0.0020\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 8s 221ms/step - loss: 0.0019\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 4s 111ms/step - loss: 0.0018\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 4s 94ms/step - loss: 0.0020\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.0018\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 3s 88ms/step - loss: 0.0017\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 3s 87ms/step - loss: 0.0018\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 3s 88ms/step - loss: 0.0017\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 4s 98ms/step - loss: 0.0018\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 0.0017\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 3s 88ms/step - loss: 0.0019\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.0018\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 4s 93ms/step - loss: 0.0018\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 0.0016\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 4s 93ms/step - loss: 0.0015\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 0.0013\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 4s 108ms/step - loss: 0.0016\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 4s 97ms/step - loss: 0.0015\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 4s 92ms/step - loss: 0.0016\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 3s 86ms/step - loss: 0.0015\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.0015\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 3s 87ms/step - loss: 0.0018\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 3s 92ms/step - loss: 0.0017\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 3s 84ms/step - loss: 0.0014\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 3s 83ms/step - loss: 0.0016\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 3s 88ms/step - loss: 0.0013\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 4s 94ms/step - loss: 0.0013\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.0015\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 0.0014\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 3s 86ms/step - loss: 0.0013\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 3s 87ms/step - loss: 0.0012\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 3s 84ms/step - loss: 0.0012\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 0.0013\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 3s 84ms/step - loss: 0.0012\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 0.0013\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 4s 95ms/step - loss: 0.0011\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 3s 92ms/step - loss: 0.0012\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 3s 86ms/step - loss: 0.0012\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 0.0011\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 4s 96ms/step - loss: 0.0011\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 4s 93ms/step - loss: 0.0011\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 3s 83ms/step - loss: 0.0011\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 3s 88ms/step - loss: 0.0011\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 3s 85ms/step - loss: 0.0011\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 4s 97ms/step - loss: 0.0012\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 4s 96ms/step - loss: 0.0011\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 0.0012\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 4s 100ms/step - loss: 0.0010\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 4s 96ms/step - loss: 0.0012\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 3s 88ms/step - loss: 0.0013\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 3s 89ms/step - loss: 0.0011\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 0.0010\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 3s 91ms/step - loss: 0.0011\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 3s 88ms/step - loss: 0.0012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x178414a5f10>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M0.fit(train_x,train_y,epochs=100,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20c2827d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = M0.predict(test_x)\n",
    "test_y = sc.inverse_transform(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f32d082",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_y,color = 'red', label = 'Real Price')\n",
    "plt.plot(test_y, color = 'blue', label = 'Predicted Price')\n",
    "plt.title('Google Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Google Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
